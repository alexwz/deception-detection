{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deception_use_humanbase.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDYfmv0jRP1S"
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTR-QGEm36OV"
      },
      "source": [
        "ýimport pickle\n",
        "\n",
        "all_texts = pickle.load(open('/content/drive/My Drive/psych/klamanie/dane/all_texts.pkl', 'rb'))\n",
        "all_labels = pickle.load(open('/content/drive/My Drive/psych/klamanie/dane/all_labels.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwIznmQW3Mqg"
      },
      "source": [
        "\n",
        "### ------------------------------------ USE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ4rpi-z3ZwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0b2607-e9e2-46cf-e626-fb32f476fcca"
      },
      "source": [
        "#!pip3 install tensorflow-gpu\n",
        "!pip3 install --quiet tensorflow-hub\n",
        "!pip3 install tensorflow_text #>=2.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_pJUiTT3P5a"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import tensorflow_text\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
        "#embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/2\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB4Z6cGqxEvf"
      },
      "source": [
        "\n",
        "all_embedded_texts = {}\n",
        "n=50\n",
        "\n",
        "for text_type in ['p', 't']:\n",
        "\n",
        "  all_embedded_texts[text_type] = []\n",
        "  chunks=[all_texts[text_type][i:i + n] for i in range(0, len(all_texts[text_type]), n)]  \n",
        "  for chunk in chunks:\n",
        "    all_embedded_texts[text_type].extend( embed(chunk).numpy() )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skUCOHIDNwbp"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import NuSVC\n",
        "from xgboost import XGBClassifier\n",
        "import pickle\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "\n",
        "#for kernel_type in ['rbf', 'linear']:\n",
        "kernel_type = 'rbf'\n",
        "\n",
        "use3_results = {}\n",
        "for text_type in ['p', 't']:\n",
        "\n",
        "  print(f\"{text_type} \")\n",
        "  embeddings = np.array(all_embedded_texts[text_type])\n",
        "  labels = np.array(all_labels[text_type])\n",
        "\n",
        "  use3_results[text_type] = []\n",
        "  true_labels = []\n",
        "  predicted_labels = []\n",
        "\n",
        "  foldnr=0\n",
        "  kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "  for train_index, test_index in kf.split(embeddings):\n",
        "\n",
        "    X_train, X_test = embeddings[train_index], embeddings[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    clf = NuSVC(nu=0.5, kernel=kernel_type)\n",
        "\n",
        "    model = clf.fit(X_train, y_train.ravel())\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    use3_results[text_type].append( {'y_pred':predictions , 'y_true':y_test } )\n",
        "\n",
        "    predicted_labels.extend(predictions)\n",
        "    true_labels.extend(y_test)\n",
        "\n",
        "    foldnr += 1\n",
        "\n",
        "  print(classification_report(true_labels, predicted_labels, digits=2 ))\n",
        "\n",
        "  stat, p = wilcoxon(x=predicted_labels, y=true_labels)\n",
        "  print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "  # interpret\n",
        "  alpha = 0.05\n",
        "  if p > alpha:\n",
        "    print('Same distribution (fail to reject H0)')\n",
        "  else:\n",
        "    print('Different distribution (reject H0)')\n",
        "\n",
        "\n",
        "pickle.dump(use3_results, open('/content/drive/My Drive/psych/klamanie/experiments/use3_results-svmrbf.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwWcU5pY85dz",
        "outputId": "d28b00cc-ddbf-4ba3-e2e8-9e855075f2b6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.svm import NuSVC\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "Y = np.array(labels)\n",
        "X = embeddings\n",
        "\n",
        "#for kernel_type in ['rbf', 'linear']:\n",
        "kernel_type = 'rbf'\n",
        "n = 0.05\n",
        "while n < 1.0:\n",
        "  all_predicted_y = []\n",
        "  loo = KFold(n_splits=20)\n",
        "  for train_index, test_index in loo.split(Y):\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "      clf = NuSVC(nu=n, kernel=kernel_type)\n",
        "\n",
        "      model = clf.fit(X_train, Y_train.ravel())\n",
        "      predictions = model.predict(X_test)\n",
        "      all_predicted_y.extend( predictions )\n",
        "\n",
        "  acc = accuracy_score(Y, all_predicted_y)\n",
        "  std_error = np.std( np.abs(np.subtract(Y, all_predicted_y)) ) / np.sqrt( len(all_predicted_y) )\n",
        "  print(\"nu: %1.3f accuracy: %1.4f std_error: %1.4f\" % (n, acc, std_error))\n",
        "  n += 0.05\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nu: 0.050 accuracy: 0.7082 std_error: 0.0168\n",
            "nu: 0.100 accuracy: 0.7055 std_error: 0.0169\n",
            "nu: 0.150 accuracy: 0.7041 std_error: 0.0169\n",
            "nu: 0.200 accuracy: 0.7041 std_error: 0.0169\n",
            "nu: 0.250 accuracy: 0.6986 std_error: 0.0170\n",
            "nu: 0.300 accuracy: 0.6986 std_error: 0.0170\n",
            "nu: 0.350 accuracy: 0.7041 std_error: 0.0169\n",
            "nu: 0.400 accuracy: 0.7014 std_error: 0.0169\n",
            "nu: 0.450 accuracy: 0.7055 std_error: 0.0169\n",
            "nu: 0.500 accuracy: 0.7151 std_error: 0.0167\n",
            "nu: 0.550 accuracy: 0.7123 std_error: 0.0168\n",
            "nu: 0.600 accuracy: 0.7110 std_error: 0.0168\n",
            "nu: 0.650 accuracy: 0.7151 std_error: 0.0167\n",
            "nu: 0.700 accuracy: 0.7096 std_error: 0.0168\n",
            "nu: 0.750 accuracy: 0.7164 std_error: 0.0167\n",
            "nu: 0.800 accuracy: 0.7192 std_error: 0.0166\n",
            "nu: 0.850 accuracy: 0.7205 std_error: 0.0166\n",
            "nu: 0.900 accuracy: 0.7041 std_error: 0.0169\n",
            "nu: 0.950 accuracy: 0.6808 std_error: 0.0173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKPUNaWsQH7b",
        "outputId": "be1ad703-6e66-4fe2-d0da-8ac4ad576ac0"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.svm import NuSVC\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "for text_type in ['p', 't']:\n",
        "\n",
        "  print(f\"{text_type} \")\n",
        "\n",
        "  Y = np.array(all_labels[text_type])\n",
        "  X = np.array(all_embedded_texts[text_type])\n",
        "\n",
        "  #for kernel_type in ['rbf', 'linear']:\n",
        "  kernel_type = 'rbf'\n",
        "  n = 0.05\n",
        "  while n < 1.0:\n",
        "    all_predicted_y = []\n",
        "    loo = KFold(n_splits=20)\n",
        "    for train_index, test_index in loo.split(Y):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "        clf = NuSVC(nu=n, kernel=kernel_type)\n",
        "\n",
        "        model = clf.fit(X_train, Y_train.ravel())\n",
        "        predictions = model.predict(X_test)\n",
        "        all_predicted_y.extend( predictions )\n",
        "\n",
        "    acc = accuracy_score(Y, all_predicted_y)\n",
        "    std_error = np.std( np.abs(np.subtract(Y, all_predicted_y)) ) / np.sqrt( len(all_predicted_y) )\n",
        "    print(\"nu: %1.3f accuracy: %1.4f std_error: %1.4f\" % (n, acc, std_error))\n",
        "    n += 0.05\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p \n",
            "nu: 0.050 accuracy: 0.6697 std_error: 0.0171\n",
            "nu: 0.100 accuracy: 0.6697 std_error: 0.0171\n",
            "nu: 0.150 accuracy: 0.6711 std_error: 0.0171\n",
            "nu: 0.200 accuracy: 0.6684 std_error: 0.0171\n",
            "nu: 0.250 accuracy: 0.6671 std_error: 0.0171\n",
            "nu: 0.300 accuracy: 0.6697 std_error: 0.0171\n",
            "nu: 0.350 accuracy: 0.6764 std_error: 0.0170\n",
            "nu: 0.400 accuracy: 0.6869 std_error: 0.0169\n",
            "nu: 0.450 accuracy: 0.6909 std_error: 0.0168\n",
            "nu: 0.500 accuracy: 0.6869 std_error: 0.0169\n",
            "nu: 0.550 accuracy: 0.6856 std_error: 0.0169\n",
            "nu: 0.600 accuracy: 0.6843 std_error: 0.0169\n",
            "nu: 0.650 accuracy: 0.6737 std_error: 0.0170\n",
            "nu: 0.700 accuracy: 0.6684 std_error: 0.0171\n",
            "nu: 0.750 accuracy: 0.6539 std_error: 0.0173\n",
            "nu: 0.800 accuracy: 0.6539 std_error: 0.0173\n",
            "nu: 0.850 accuracy: 0.6367 std_error: 0.0175\n",
            "nu: 0.900 accuracy: 0.6341 std_error: 0.0175\n",
            "nu: 0.950 accuracy: 0.5945 std_error: 0.0178\n",
            "t \n",
            "nu: 0.050 accuracy: 0.6521 std_error: 0.0176\n",
            "nu: 0.100 accuracy: 0.6493 std_error: 0.0177\n",
            "nu: 0.150 accuracy: 0.6493 std_error: 0.0177\n",
            "nu: 0.200 accuracy: 0.6507 std_error: 0.0176\n",
            "nu: 0.250 accuracy: 0.6521 std_error: 0.0176\n",
            "nu: 0.300 accuracy: 0.6466 std_error: 0.0177\n",
            "nu: 0.350 accuracy: 0.6479 std_error: 0.0177\n",
            "nu: 0.400 accuracy: 0.6438 std_error: 0.0177\n",
            "nu: 0.450 accuracy: 0.6493 std_error: 0.0177\n",
            "nu: 0.500 accuracy: 0.6575 std_error: 0.0176\n",
            "nu: 0.550 accuracy: 0.6603 std_error: 0.0175\n",
            "nu: 0.600 accuracy: 0.6658 std_error: 0.0175\n",
            "nu: 0.650 accuracy: 0.6603 std_error: 0.0175\n",
            "nu: 0.700 accuracy: 0.6603 std_error: 0.0175\n",
            "nu: 0.750 accuracy: 0.6507 std_error: 0.0176\n",
            "nu: 0.800 accuracy: 0.6603 std_error: 0.0175\n",
            "nu: 0.850 accuracy: 0.6425 std_error: 0.0177\n",
            "nu: 0.900 accuracy: 0.6164 std_error: 0.0180\n",
            "nu: 0.950 accuracy: 0.5973 std_error: 0.0182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbPXBHYP83_F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold, GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7lNt9N9RUd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvGn_JNDzLZf"
      },
      "source": [
        "import pickle\n",
        "\n",
        "use3_results = pickle.load(open('/content/drive/My Drive/psych/klamanie/experiments/use3_results-svmrbf.pkl','rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35SH7b_sB0nW",
        "outputId": "a9e8ed81-9ddd-4045-e117-fe5a9ad53b6b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# http://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/\n",
        "from mlxtend.evaluate import cochrans_q\n",
        "\n",
        "import numpy as np\n",
        "all_results = pickle.load( open('/content/drive/My Drive/psych/klamanie/experiments/in_domain_results.pkl','rb'))\n",
        "\n",
        "#model_results = { 'report':report, 'y_pred':y_pred, 'y_true':y_test , 'fold_nr':fold_nr, 'model':BERT_MODEL['name'], 'text_type':text_type }\n",
        "#all_results[text_type].append(model_results)\n",
        "\n",
        "\n",
        "for text_type in ['p', 't']:\n",
        "  print(f\"text type: {text_type}\")  \n",
        "  y_pred = {}\n",
        "  y_true = {}\n",
        "\n",
        "  for result_dict in all_results[text_type]:\n",
        "    if result_dict['model'] not in y_pred:\n",
        "      y_pred[ result_dict['model'] ] = []\n",
        "      y_true[ result_dict['model'] ] = []\n",
        "    y_pred[ result_dict['model'] ].extend( result_dict['y_pred'].astype(int) )\n",
        "    y_true[ result_dict['model'] ].extend( result_dict['y_true'].astype(int) )\n",
        "\n",
        "  #use3_results[text_type].append( {'y_pred':predictions , 'y_true':y_test } )\n",
        "  y_pred['use3'] = []\n",
        "  for result_dict in use3_results[text_type]:\n",
        "    y_pred['use3'].extend( result_dict['y_pred'] )\n",
        "\n",
        "  q, p_value = cochrans_q(np.array(y_true['bert-base-uncased']), \n",
        "                          np.array(y_pred['allegro/herbert-base-cased']), \n",
        "                          np.array(y_pred['use3']) )\n",
        "\n",
        "  print('Q: %.3f' % q)\n",
        "  print('p-value: %.3f' % p_value)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text type: p\n",
            "Q: 0.067\n",
            "p-value: 0.796\n",
            "text type: t\n",
            "Q: 0.097\n",
            "p-value: 0.756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlxtend/evaluate/cochrans_q.py:75: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  mod in y_model_predictions)).astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMHmyZVyLtcC"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "human baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqgJmUsOLZkZ",
        "outputId": "c7e78c3a-2016-41f4-c57a-4e3fee01eecd"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "# http://rasbt.github.io/mlxtend/user_guide/evaluate/cochrans_q/\n",
        "from mlxtend.evaluate import cochrans_q\n",
        "# https://machinelearningmastery.com/nonparametric-statistical-significance-tests-in-python/\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "print('-'*20)\n",
        "print('pisemne')\n",
        "\n",
        "tresh = 2\n",
        "\n",
        "y_true = [] ; y_pred = []\n",
        "df = pd.read_excel('/content/drive/My Drive/psych/klamanie/experiments/p_czy_k_Aleks.xlsx', sheet_name='pisemne', index_col=None, header=0)\n",
        "df = df.fillna('')\n",
        "for index, row in df.iterrows():\n",
        "  if row['id_t'] is not '' or row['id_f'] is not '':\n",
        "\n",
        "    #print(row['id_t'], row['wiar_prawda'], row['id_f'], row['wiar_kłamstwo'] )\n",
        "\n",
        "    if row['wiar_prawda'] is not '':\n",
        "      if int(row['wiar_prawda']) >= tresh:\n",
        "        y_true.append(1) ; y_pred.append(1)\n",
        "      else:\n",
        "        y_true.append(1) ; y_pred.append(0)\n",
        "        \n",
        "    if row['wiar_kłamstwo'] is not '':\n",
        "      if int(row['wiar_kłamstwo']) >= tresh:\n",
        "        y_true.append(0) ; y_pred.append(0)\n",
        "      else:\n",
        "        y_true.append(0) ; y_pred.append(1)\n",
        "\n",
        "  else:\n",
        "    break\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=2 ))  \n",
        "stat, p = wilcoxon(y_true, y_pred)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distribution (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distribution (reject H0)')\n",
        "\n",
        "\n",
        "print('-'*20)\n",
        "print('transkrypcje')\n",
        "\n",
        "y_true = [] ; y_pred = []\n",
        "df = pd.read_excel('/content/drive/My Drive/psych/klamanie/experiments/p_czy_k_Aleks.xlsx', sheet_name='transkrypcje', index_col=None, header=0)\n",
        "df = df.fillna('')\n",
        "for index, row in df.iterrows():\n",
        "  if row['id_t'] is not '' or row['id_f'] is not '':\n",
        "    #print(row['id_t'], row['wiar_prawda'], row['id_f'], row['wiar_kłamstwo'] )\n",
        "\n",
        "    if row['wiar_prawda'] is not '':\n",
        "      if int(row['wiar_prawda']) >= tresh:\n",
        "        y_true.append(1) ; y_pred.append(1)\n",
        "      else:\n",
        "        y_true.append(1) ; y_pred.append(0)\n",
        "        \n",
        "    if row['wiar_kłamstwo'] is not '':\n",
        "      if int(row['wiar_kłamstwo']) >= tresh:\n",
        "        y_true.append(0) ; y_pred.append(0)\n",
        "      else:\n",
        "        y_true.append(0) ; y_pred.append(1)\n",
        "\n",
        "  else:\n",
        "    break\n",
        "\n",
        "print(classification_report(y_true, y_pred, digits=2 ))  \n",
        "stat, p = wilcoxon(y_true, y_pred)\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Same distribution (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Different distribution (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "pisemne\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.53      0.55       381\n",
            "           1       0.56      0.60      0.58       380\n",
            "\n",
            "    accuracy                           0.56       761\n",
            "   macro avg       0.56      0.56      0.56       761\n",
            "weighted avg       0.56      0.56      0.56       761\n",
            "\n",
            "Statistics=25551.000, p=0.139\n",
            "Same distribution (fail to reject H0)\n",
            "--------------------\n",
            "transkrypcje\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.41      0.50       367\n",
            "           1       0.56      0.75      0.64       367\n",
            "\n",
            "    accuracy                           0.58       734\n",
            "   macro avg       0.59      0.58      0.57       734\n",
            "weighted avg       0.59      0.58      0.57       734\n",
            "\n",
            "Statistics=14014.000, p=0.000\n",
            "Different distribution (reject H0)\n"
          ]
        }
      ]
    }
  ]
}